{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script trains the model camera\n",
    "# Augmentation: Individual images are randomly augmented\n",
    "\n",
    "import sys\n",
    "#adjust your path correspondingly, make sure to import the DS theory libs\n",
    "sys.path.insert(0,'../libs')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from datetime import datetime, timedelta\n",
    "from utils import train_val_split, split_check, write_path, kittiroadRGB\n",
    "from ds_layer_p2p import DS1_activate functions \n",
    "import tensorflow as tf\n",
    "\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "## Memory settings\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "## ---- end Memory setting ----\n",
    "\n",
    "#============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to be updated\n",
    "input_dir_rgb=\"../image_2/\"\n",
    "target_dir=\"../semantic_rgb/\"\n",
    "\n",
    "out_dir= \"../output/\"\n",
    "model_dir= \"../model_arch/\"\n",
    "\n",
    "#zero weights\n",
    "# Load model arch\n",
    "dir_name = os.path.join(model_dir,\"camera_model\")\n",
    "model=keras.models.load_model(dir_name,custom_objects={'DS1_activate': DS1_activate})\n",
    "\n",
    "model.summary()\n",
    "\n",
    "######################################################################################\n",
    "# input size\n",
    "img_size = (384,1248)\n",
    "batch_size = 1\n",
    "\n",
    "#Prepare paths of input images and target segmentation masks   \n",
    "data_split= train_val_split( input_dir_rgb, target_dir)\n",
    "train_input_img_paths_rgb= data_split[\"train_cam_1\"]  # path of camera images, training\n",
    "train_target_img_paths= data_split[\"train_target_1\"]     # path of target image, training\n",
    "val_input_img_paths_rgb= data_split[\"val_cam_1\"]    # path of camera images, validation\n",
    "val_target_img_paths= data_split[\"val_target_1\"]       # path of taget image, validation \n",
    "\n",
    "# prepare split matching\n",
    "train_cam= split_check(train_input_img_paths_rgb)\n",
    "train_target= split_check(train_target_img_paths)\n",
    "val_cam= split_check(val_input_img_paths_rgb)\n",
    "val_target= split_check(val_target_img_paths)\n",
    "\n",
    "\n",
    "# write split paths to a text file\n",
    "#paths to be updated\n",
    "write_path(out_dir, train_input_img_paths_rgb, 'train_input_img_paths_rgb.txt')\n",
    "write_path(out_dir, train_target_img_paths, 'train_target_img_paths.txt')\n",
    "\n",
    "write_path(out_dir, val_input_img_paths_rgb, 'val_input_img_paths_rgb.txt')\n",
    "write_path(out_dir, val_target_img_paths, 'val_target_img_paths.txt')\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = kittiroadRGB(batch_size, img_size, train_input_img_paths_rgb, train_target_img_paths)\n",
    "val_gen = kittiroadRGB(batch_size, img_size, val_input_img_paths_rgb, val_target_img_paths,val=True)\n",
    "\n",
    "# Configure the model for training.\n",
    "# Polynomial Decay  \n",
    "starter_learning_rate=0.0005\n",
    "end_learning_rate=0\n",
    "epochs = 500\n",
    "decay_steps=261*epochs # 261(frames) x (nr_epoch) \n",
    "lr_schedule=keras.optimizers.schedules.PolynomialDecay(starter_learning_rate, decay_steps,end_learning_rate,power=0.9)\n",
    "\n",
    "# Optimizer\n",
    "opt=keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=opt, loss= keras.losses.MeanSquaredError(), metrics= [\"mse\"])\n",
    "\n",
    "# Modelcheckpoint\n",
    "model_checkpoint_callback=keras.callbacks.ModelCheckpoint(\n",
    "filepath= os.path.join(out_dir,'checkpoint_camera_model'),\n",
    "save_weights_only=True,\n",
    "monitor='val_loss', \n",
    "mode='min',\n",
    "save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "st_time= datetime.now()\n",
    "history= model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=[model_checkpoint_callback])\n",
    "end_time= datetime.now()\n",
    "\n",
    "# Save training miscellaneous results\n",
    "elapsed_total_sec= (end_time - st_time).total_seconds()\n",
    "conversion = timedelta(seconds= elapsed_total_sec)\n",
    "\n",
    "with open(os.path.join(out_dir, 'time_log.txt'), 'w') as f:\n",
    "    f.write('%s\\n' %'Training time in H:M:S')\n",
    "    f.write( str(conversion))\n",
    "    f.close()\n",
    "\n",
    "np.savez_compressed(os.path.join(out_dir,'history.npz'), loss= history.history['loss'], \n",
    "                val_loss= history.history['val_loss'], \n",
    "               accuracy= history.history['mse'],\n",
    "               val_accuracy= history.history['val_mse'] )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
